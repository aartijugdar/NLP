{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData=pd.read_csv(\"C:\\\\Users\\\\jugdar_a\\\\Downloads\\\\train_E6oV3lV.csv\",delimiter=\",\")\n",
    "testData=pd.read_csv(\"C:\\\\Users\\\\jugdar_a\\\\Downloads\\\\test_tweets_anuFYb8.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " stopword_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['tweet']=np.vectorize(remove_pattern)(trainData['tweet'], \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['tweet']=np.vectorize(remove_pattern)(testData['tweet'],\"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      when a father is dysfunctional and is so sel...\n",
       "1      thanks for lyft credit i cant use cause they...\n",
       "2                                  bihday your majesty\n",
       "3    model   i love u take with u all the time in u...\n",
       "4                 factsguide society now    motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['tweet'] = trainData['tweet'].str.replace('[^\\w\\s]','')\n",
    "trainData['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    studiolife aislife requires passion dedication...\n",
       "1      white supremacists want everyone to see the ...\n",
       "2    safe ways to heal your acne    altwaystoheal h...\n",
       "3    is the hp and the cursed child book up for res...\n",
       "4      3rd bihday to my amazing hilarious nephew el...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData['tweet'] = testData['tweet'].str.replace('[^\\w\\s]','')\n",
    "testData['tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    when a father is dysfunctional and is so selfi...\n",
       "1    thanks for lyft credit i cant use cause they d...\n",
       "2                                  bihday your majesty\n",
       "3    model i love u take with u all the time in ur√∞...\n",
       "4                    factsguide society now motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['tweet'] = trainData['tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "trainData['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    studiolife aislife requires passion dedication...\n",
       "1    white supremacists want everyone to see the ne...\n",
       "2    safe ways to heal your acne altwaystoheal heal...\n",
       "3    is the hp and the cursed child book up for res...\n",
       "4    3rd bihday to my amazing hilarious nephew eli ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData['tweet'] = testData['tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "testData['tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drags kids dysfun...\n",
       "1    thanks lyft credit cant use cause dont offer w...\n",
       "2                                       bihday majesty\n",
       "3                model love u take u time ur√∞ √∞√∞√∞√∞ √∞√∞√∞\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['tweet'] = trainData['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stopword_set))\n",
    "trainData['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    studiolife aislife requires passion dedication...\n",
       "1    white supremacists want everyone see new √¢ bir...\n",
       "2    safe ways heal acne altwaystoheal healthy healing\n",
       "3    hp cursed child book reservations already yes ...\n",
       "4    3rd bihday amazing hilarious nephew eli ahmir ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData['tweet'] = testData['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stopword_set))\n",
    "testData['tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "#Regular expression for removing everything other than alphabets and spaces\n",
    "reg = re.compile(\"[^a-zA-Z ]\")  \n",
    "spa = re.compile(\"[+ ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drags kids dysfun...\n",
       "1    thanks lyft credit cant use cause dont offer w...\n",
       "2                                       bihday majesty\n",
       "3                model love u take u time ur√∞ √∞√∞√∞√∞ √∞√∞√∞\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['tweet'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replaceing unwanted characters with null\n",
    "trainData['tweet'].replace(reg,'',inplace=True)\n",
    "trainData['tweet'].replace(spa,' ',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drags kids dysfun...\n",
       "1    thanks lyft credit cant use cause dont offer w...\n",
       "2                                       bihday majesty\n",
       "3                        model love u take u time ur  \n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['tweet'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replaceing unwanted characters with null\n",
    "testData['tweet'].replace(reg,'',inplace=True)\n",
    "testData['tweet'].replace(spa,' ',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_lengthening(text):\n",
    "    pattern_ln = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern_ln.sub(r\"\\1\\1\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['tweet']=trainData['tweet'].apply(lambda x: \" \".join(reduce_lengthening(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['tweet']=testData['tweet'].apply(lambda x: \" \".join(reduce_lengthening(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drags kids dysfun...\n",
       "1    thanks lyft credit cant use cause dont offer w...\n",
       "2                                       bihday majesty\n",
       "3                          model love u take u time ur\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['tweet'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    studiolife aislife requires passion dedication...\n",
       "1    white supremacists want everyone see new birds...\n",
       "2    safe ways heal acne altwaystoheal healthy healing\n",
       "3    hp cursed child book reservations already yes ...\n",
       "4    rd bihday amazing hilarious nephew eli ahmir u...\n",
       "5                                       choose momtips\n",
       "6    something inside dies eyes ness smokeyeyes tir...\n",
       "7              finishedtattooinkedinkloveit thanksalee\n",
       "8      never understand dad left young deep inthefeels\n",
       "9    delicious food lovelife capetown mannaepicure ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData['tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spelling\n",
      "final\n",
      "mistakes\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "WORDS = Counter(words(open('C:/Users/jugdar_a/Downloads/big.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "    \n",
    "\"\"\"\n",
    "Exemple avec des mots au hasard \n",
    "\"\"\"\n",
    "print(correction('speling'))\n",
    "print(correction('fial'))\n",
    "print(correction(\"misstkaes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['tweet']=trainData['tweet'].apply(lambda x: \" \".join(correction(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drags kids dysfun...\n",
       "1    thanks lyft credit cant use cause dont offer w...\n",
       "2                                       bihday majesty\n",
       "3                          model love u take u time ur\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['tweet'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['tweet']=testData['tweet'].apply(lambda x: \" \".join(correction(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    studiolife dislike requires passion education ...\n",
       "1    user white supremacists want everyone see new ...\n",
       "2    safe ways heal acne altwaystoheal healthy healing\n",
       "3    he cursed child book reservations already yes ...\n",
       "4    rd midday amazing hilarious nephew epi their u...\n",
       "5                                       choose momtips\n",
       "6    something inside dies eyes ness smokeyeyes tir...\n",
       "7            finishedtattooinkedinkloveit thanksaleeee\n",
       "8    user user user never understand dad left young...\n",
       "9    delicious food lovelife capetown mannaepicure ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData['tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['token_length'] = [len(x.split(\" \")) for x in trainData.tweet]\n",
    "max(trainData.token_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jugdar_a\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=20000) #Tokenizer is used to tokenize text\n",
    "tokenizer.fit_on_texts(trainData.tweet) #Fit this to our corpus\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(trainData.tweet) #'text to sequences converts the text to a list of indices\n",
    "x_train = pad_sequences(x_train, maxlen=100) #pad_sequences makes every sequence a fixed size list by padding with 0s \n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=tokenizer.texts_to_sequences(testData['tweet'])\n",
    "x_test=pad_sequences(x_test,maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 1196, 8725,   95],\n",
       "       [   0,    0,    0, ...,  496,  379,  732],\n",
       "       [   0,    0,    0, ...,   99,   28,  166],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   60, 1603,  130],\n",
       "       [   0,    0,    0, ...,  578,   27,  243],\n",
       "       [   0,    0,    0, ..., 1425, 2899, 8809]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39515\n"
     ]
    }
   ],
   "source": [
    "token_index=len(tokenizer.word_index)\n",
    "print(token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31962, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical # This convers the labels to one-hot vectors(Dummies)\n",
    "\n",
    "unique_labels = list(trainData.label.unique()) \n",
    "y_train = np.array([unique_labels.index(i) for i in trainData.label]) # Convert the word labels to indeces\n",
    "y_train = to_categorical(y_train) # Dummify the labels\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=trainData.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Conv1D, Embedding,MaxPooling1D,GlobalMaxPooling1D,LSTM,Dropout,Bidirectional,TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras import callbacks\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import recall_score\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jugdar_a\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=2)`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#required variables\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_acc', patience=2, verbose=0, mode='auto')\n",
    "  \n",
    "  \n",
    "    #model initialization  # Call Sequential to initialize a network\n",
    "model_conv = Sequential()\n",
    "   \n",
    "model_conv.add(Embedding(input_dim=token_index,input_length=100, output_dim=100))\n",
    "model_conv.add(Dropout(0.1))\n",
    "model_conv.add(Conv1D(32, 1, activation='relu'))\n",
    "model_conv.add(MaxPooling1D(pool_size=4))\n",
    "model_conv.add(Bidirectional(LSTM(100,return_sequences=False)))\n",
    "model_conv.add(Dense(output_dim=2, activation='softmax'))\n",
    "model_conv.compile(optimizer='rmsprop',  # 'Adam' is a variant of gradient descent technique\n",
    "              loss='binary_crossentropy', # categorical_crossentropy for multi-class classification\n",
    "              metrics=['accuracy'])# These metrics are computed and printed for evaluating\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31962/31962 [==============================] - 517s 16ms/step - loss: 0.1789 - acc: 0.9421\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jugdar_a\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:535: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31962/31962 [==============================] - 553s 17ms/step - loss: 0.1226 - acc: 0.9590\n",
      "Epoch 3/10\n",
      "31962/31962 [==============================] - 562s 18ms/step - loss: 0.1020 - acc: 0.9667\n",
      "Epoch 4/10\n",
      "31962/31962 [==============================] - 567s 18ms/step - loss: 0.0901 - acc: 0.9709\n",
      "Epoch 5/10\n",
      "31962/31962 [==============================] - 563s 18ms/step - loss: 0.0817 - acc: 0.9741\n",
      "Epoch 6/10\n",
      "31962/31962 [==============================] - 558s 17ms/step - loss: 0.0754 - acc: 0.9763\n",
      "Epoch 7/10\n",
      "31962/31962 [==============================] - 560s 18ms/step - loss: 0.0694 - acc: 0.9784\n",
      "Epoch 8/10\n",
      "31962/31962 [==============================] - 552s 17ms/step - loss: 0.0627 - acc: 0.9802\n",
      "Epoch 9/10\n",
      "31962/31962 [==============================] - 546s 17ms/step - loss: 0.0577 - acc: 0.9822\n",
      "Epoch 10/10\n",
      "31962/31962 [==============================] - 496s 16ms/step - loss: 0.0535 - acc: 0.9837\n"
     ]
    }
   ],
   "source": [
    "model_conv.fit(x_train, y=y_train,batch_size=32,\n",
    "          epochs=10,callbacks=[early_stop])\n",
    "# Creates a HDF5 file 'my_model.h5'\n",
    "model_conv.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model \n",
    "model = load_model(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.9280248e-01, 1.0719754e-01],\n",
       "       [8.2137656e-01, 1.7862342e-01],\n",
       "       [9.9997401e-01, 2.5960473e-05],\n",
       "       ...,\n",
       "       [9.9878258e-01, 1.2173813e-03],\n",
       "       [9.9995279e-01, 4.7162401e-05],\n",
       "       [9.9447036e-01, 5.5296449e-03]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred=np.argmax(prediction,axis=1) #applying for rows ..in numpy 1 is row\n",
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=pd.DataFrame(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16132\n",
       "1     1065\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('prediction9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
